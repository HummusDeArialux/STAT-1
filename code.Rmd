---
title: "PAC 1 Regresión Lineal"
author: "Maria Lucas"
date: "2023-04-22"
output: pdf_document
---
\newpage

# Ejercicio 1

Primero, cargamos los datos del documento excel.
```{r}
#install.packages("readxl")
library("readxl")
data1 = read_excel("cicindela.xlsx")
names(data1)[1] <- "BD"
names(data1)[2] <- "WE"
names(data1)[3] <- "SPS"
names(data1)[4] <- "BS"
names(data1)[5] <- "AD"
```

### (a) Ajuste del modelo

LA IA ME DICE QUE CHECKEE LAS ASUNCIONES (lineal, independencia, homocedasticidad, N de residuos)

```{r}
# Creación del modelo
lmod = lm(BD ~ WE + SPS + BS + AD, data = data1)
sum = summary(lmod)
sum
```

Como podemos observar mediante la estimación de los coeficientes de regresión, la ecuación quedaría como: BD = 14.95 + 0.91WE + 3.89SPS + 0.65BS - 1.56AD.

El modelo obtenido es significativo, con un pvalor global = 6.727e-05. El test estadístico empleado es un F-test, éste testa como H0 que todos los coeficientes de regresión son 0, y como H1 que al menos uno es distinto de 0. 

  - H0: $\beta1 = \beta2 =$...$=\beta$p = 0 (donde $\beta1$, $\beta2$, ..., $\beta$p son los coeficientes de regresión de las variables predictoras del modelo)
  - H1: al menos un $\beta$i es diferente a 0, donde i = 1, 2, ..., p

En este caso al menos una de las variables tiene dependencia lineal con la variable respuesta (Beetle Density), ya que el pvalor es menor a 0.05 y por lo tanto, rechazamos la H0. 

Tal y como se ve en la tabla de coeficientes, tanto SPS (Sand Particle Size, pvalor = 0.01) como AD (Amphipod Density, pvalor = 0.05) tienen un impacto significativo sobre la variable respuesta.

### (b) Intervalos de confianza para AmphipodDensity

```{r}
# CI a 95%
confint(lmod, "AD", level = 0.95)
# CI a 90%
confint(lmod, "AD", level = 0.9)
```

En ninguno de los dos intervalos se incluye el 0, es por ello que podemos deducir que el pvalor sea significativo a un nivel de confianza de 0.1 y 0.05, ya que como hemos explicado medimos si el parámetro es distinto a 0. 

El coeficiente de regresión representa el cambio de la variable respuesta (BD o Beetle Density) por cada unidad que aumenta la variable predictora AD. Si este valor es 0 significa que la variable respuesta no varia conforme cambia el valor de la variable predictora. Si el valor es positivo un incremento de AD supone un incremento de BD, y si el valor es negativo un incremento de AD supone una reducción de BD.

### (c) Multicolinealidad

```{r}
library(car)
vif(lmod)
```

El factor de inflación de la varianza o VIF mide cuánto se incrementa la varianza de los coeficientes de regresión estimados a causa de la colinealidad entre las variables predictoras. Valores de 1 indican que no hay correlación, valores de 1 a 5 que hay una ligera o moderada correlación, y valores mayores a 5 que las variables están altamente correlacionadas.

En este caso, podemos ver que sobretodo para AD hay una alta correlación y que por lo tanto no nos podemos fiar de la estimación de parámetros y pvalor. 

El umbral del nivel de correlación aceptable entre variables dependerá de cada caso de estudio concreto.

### (d) Modelo reducido

```{r}
lmod_red= lm(BD ~ SPS + AD, data = data1)
summary(lmod_red)
anova(lmod_red, lmod)
```

- H0: El modelo reducido es igual de bueno que el modelo con más variables. 
- H1: El modelo con más variables explica mejor los datos.

O si lo escribimos de forma paramétrica:

- H0: RSS_reducido = RSS_completo
- H1: RSS_reducido > RSS_completo

Cabe destacar que el RSS (Residual Sum of Squares) mide la diferencia entre los valores reales de la variable respuesta y los valores predichos por el modelo. En otras palabras, es una medida de lo bien que se ajusta el modelo a los datos. Mediante la comparación de éste parámetro el F test nos ayuda a determinar si la adición de variables y con ello el aumento de grados de libertad mejoran el ajuste del modelo.

En nuestro caso como el pvalor = 0.35 aceptamos la hipótesis nula, el modelo BD ~ SPS + AD explica igual de bien los datos que el modelo con más variables, al ser más sencillo pero con iguales resultados, lo escogeríamos antes que el modelo más complejo. 

Por otro lado, en el modelo reducido todas las variables explican de manera significa la variable respuesta. Además, el valor de R ajustado es similar en ambos modelos (0.93), este valor indica el porcentaje de la variable respuesta que es explicado por el modelo.

### (e) Gráfico región de confianza

```{r}
# install.packages('ellipse')
library(ellipse)
plot(ellipse(lmod_red, 2:3),type="l", xlim = c(-1, 8), ylim = c(-4, 1))
points(coef(lmod_red)[2], coef(lmod_red)[3], pch=19)
points(x=0, y=0, pch=19, col="blue")
abline(v=confint(lmod_red)[2,],lty=2,col=2)
abline(h=confint(lmod_red)[3,],lty=2,col=2)
```



El origen de coordenadas nos indica el resultado del test de Wald bajo las siguientes hipótesis:

- H0: $\beta1 = \beta2 = 0$. Los coeficientes de ambas variables son 0
- H1: $\beta1\neq0$ y/o $\beta2\neq0$. Caso contrario, al menos uno de los coeficientes es 0

Cuando la elipse de confianza incluye el (0,0) indica que los coeficientes estimados no son distintos que 0 y que por lo tanto las variables predictoras no aportan al modelo. Por otro lado, si no lo incluye significa que los coeficientes son distintos a 0 y las variables sí explican la variable respuesta. En este caso al no incluirlo, podemos deducir que las variables SPS y AD sí explican la variable BD.

### (f) Predicción 

```{r}
new_ob = data.frame(SPS = 5, AD = 11)
pred <- predict(lmod_red, new_ob, interval = "confidence", level = 0.95)
cat("Predicted value:", pred[1], "\n")
cat("95% confidence interval:", pred[2], "-", pred[3])
```

```{r}
#install.packages('regclass')
library(regclass)
extrapolation_check(lmod_red,new_ob)
```

```{r}
# create a scatter plot of SPS and AD
plot(SPS ~ AD, data = data1)

# add the observed values as points on the plot
points(x = 11, y = 5, col = "red", pch = 19)

# add a legend to the plot
legend("topright", legend = c("Observed values"), col = c("red"), pch = 19)
```

En este paquete (regclass) percentiles de aproximadamente 99 pueden implicar extrapolación, en nuestro caso obtenemos un percentil de 25 indicando que seguramente no la haya. Si revisamos el scatterplot podemos ver que estos valores de SPS y AD entran dentro del scope del modelo.

# Ejercicio 2

### Gráfico de dispersión

```{r}
#install.packages("readxl")
library("readxl")
data2 = read.csv("lions.csv")
```

```{r}
library(ggplot2)
library(dplyr)

p = ggplot(data2, aes(age, prop.black))
p + geom_point(aes(shape = paste(ifelse(sex == "M", "males", "females"), ifelse(area == "N", "Ngorongoro", "Serengeti")))) + 
  scale_shape_manual(name = "", 
                     values = c(1, 19, 2, 17), 
                     labels = data2 %>%
                       group_by(sex, area) %>%
                       summarize(n = n()) %>%
                       mutate(label = paste0(ifelse(area == "N", "Ngorongoro", "Serengeti"), " ", ifelse(sex == "M", "males", "females"), "(n = ", n, ")")) %>%
                       pull(label)) +
  labs(x = "Age (yr)", y = "Proportion black", shape = "") +
  scale_x_continuous(breaks = seq(0, 16, 2), limits = c(0, 16)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  scale_fill_discrete(breaks=c('F', 'M')) +
  theme_classic() +
  theme(aspect.ratio = 0.5, legend.position = c(0.75, 0.3))
```

### Gráfico de dispersión