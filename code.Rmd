---
title: "PAC 1 Regresión Lineal"
author: "Maria Lucas"
date: "2023-04-22"
output: 
  pdf_document:
    toc: true
    toc_depth: 4
lang: Es-es
---
\newpage

# Ejercicio 1

Primero, cargamos los datos del documento excel.
```{r}
#install.packages("readxl")
library("readxl")
data1 = read_excel("cicindela.xlsx")
names(data1)[1] <- "BD"
names(data1)[2] <- "WE"
names(data1)[3] <- "SPS"
names(data1)[4] <- "BS"
names(data1)[5] <- "AD"
```

### (a) Ajuste del modelo

LA IA ME DICE QUE CHECKEE LAS ASUNCIONES (lineal, independencia, homocedasticidad, N de residuos)

```{r}
# Creación del modelo
lmod = lm(BD ~ WE + SPS + BS + AD, data = data1)
sum = summary(lmod)
sum
```

Como podemos observar mediante la estimación de los coeficientes de regresión, la ecuación quedaría como: BD = 14.95 + 0.91WE + 3.89SPS + 0.65BS - 1.56AD.

El modelo obtenido es significativo, con un pvalor global = 6.727e-05. El test estadístico empleado es un F-test, éste testa como H0 que todos los coeficientes de regresión son 0, y como H1 que al menos uno es distinto de 0. 

  - H0: $\beta1 = \beta2 =$...$=\beta$p = 0 (donde $\beta1$, $\beta2$, ..., $\beta$p son los coeficientes de regresión de las variables predictoras del modelo)
  - H1: al menos un $\beta$i es diferente a 0, donde i = 1, 2, ..., p

En este caso al menos una de las variables tiene dependencia lineal con la variable respuesta (Beetle Density), ya que el pvalor es menor a 0.05 y por lo tanto, rechazamos la H0. 

Tal y como se ve en la tabla de coeficientes, tanto SPS (Sand Particle Size, pvalor = 0.01) como AD (Amphipod Density, pvalor = 0.05) tienen un impacto significativo sobre la variable respuesta.

### (b) Intervalos de confianza para AmphipodDensity

```{r}
# CI a 95%
confint(lmod, "AD", level = 0.95)
# CI a 90%
confint(lmod, "AD", level = 0.9)
```

En ninguno de los dos intervalos se incluye el 0, es por ello que podemos deducir que el pvalor sea significativo a un nivel de confianza de 0.1 y 0.05, ya que como hemos explicado medimos si el parámetro es distinto a 0. 

El coeficiente de regresión representa el cambio de la variable respuesta (BD o Beetle Density) por cada unidad que aumenta la variable predictora AD. Si este valor es 0 significa que la variable respuesta no varia conforme cambia el valor de la variable predictora. Si el valor es positivo un incremento de AD supone un incremento de BD, y si el valor es negativo un incremento de AD supone una reducción de BD.

### (c) Multicolinealidad

```{r}
library(car)
vif(lmod)
```

El factor de inflación de la varianza o VIF mide cuánto se incrementa la varianza de los coeficientes de regresión estimados a causa de la colinealidad entre las variables predictoras. Valores de 1 indican que no hay correlación, valores de 1 a 5 que hay una ligera o moderada correlación, y valores mayores a 5 que las variables están altamente correlacionadas.

En este caso, podemos ver que sobretodo para AD hay una alta correlación y que por lo tanto no nos podemos fiar de la estimación de parámetros y pvalor. 

El umbral del nivel de correlación aceptable entre variables dependerá de cada caso de estudio concreto.

### (d) Modelo reducido

```{r}
lmod_red= lm(BD ~ SPS + AD, data = data1)
summary(lmod_red)
anova(lmod_red, lmod)
```

- H0: El modelo reducido es igual de bueno que el modelo con más variables. 
- H1: El modelo con más variables explica mejor los datos.

O si lo escribimos de forma paramétrica:

- H0: RSS_reducido = RSS_completo
- H1: RSS_reducido > RSS_completo

Cabe destacar que el RSS (Residual Sum of Squares) mide la diferencia entre los valores reales de la variable respuesta y los valores predichos por el modelo. En otras palabras, es una medida de lo bien que se ajusta el modelo a los datos. Mediante la comparación de éste parámetro el F test nos ayuda a determinar si la adición de variables y con ello el aumento de grados de libertad mejoran el ajuste del modelo.

En nuestro caso como el pvalor = 0.35 aceptamos la hipótesis nula, el modelo BD ~ SPS + AD explica igual de bien los datos que el modelo con más variables, al ser más sencillo pero con iguales resultados, lo escogeríamos antes que el modelo más complejo. 

Por otro lado, en el modelo reducido todas las variables explican de manera significa la variable respuesta. Además, el valor de R ajustado es similar en ambos modelos (0.93), este valor indica el porcentaje de la variable respuesta que es explicado por el modelo.

### (e) Gráfico región de confianza

```{r}
# install.packages('ellipse')
library(ellipse)
plot(ellipse(lmod_red, 2:3),type="l", xlim = c(-1, 8), ylim = c(-4, 1))
points(coef(lmod_red)[2], coef(lmod_red)[3], pch=19)
points(x=0, y=0, pch=19, col="blue")
abline(v=confint(lmod_red)[2,],lty=2,col=2)
abline(h=confint(lmod_red)[3,],lty=2,col=2)
```



El origen de coordenadas nos indica el resultado del test de Wald bajo las siguientes hipótesis:

- H0: $\beta1 = \beta2 = 0$. Los coeficientes de ambas variables son 0
- H1: $\beta1\neq0$ y/o $\beta2\neq0$. Caso contrario, al menos uno de los coeficientes es 0

Cuando la elipse de confianza incluye el (0,0) indica que los coeficientes estimados no son distintos que 0 y que por lo tanto las variables predictoras no aportan al modelo. Por otro lado, si no lo incluye significa que los coeficientes son distintos a 0 y las variables sí explican la variable respuesta. En este caso al no incluirlo, podemos deducir que las variables SPS y AD sí explican la variable BD.

### (f) Predicción 

```{r}
new_ob = data.frame(SPS = 5, AD = 11)
pred <- predict(lmod_red, new_ob, interval = "confidence", level = 0.95)
cat("Predicted value:", pred[1], "\n")
cat("95% confidence interval:", pred[2], "-", pred[3])
```

```{r}
#install.packages('regclass')
library(regclass)
extrapolation_check(lmod_red,new_ob)
```

```{r}
# create a scatter plot of SPS and AD
plot(SPS ~ AD, data = data1)

# add the observed values as points on the plot
points(x = 11, y = 5, col = "red", pch = 19)

# add a legend to the plot
legend("topright", legend = c("Observed values"), col = c("red"), pch = 19)
```

En este paquete (regclass) percentiles de aproximadamente 99 pueden implicar extrapolación, en nuestro caso obtenemos un percentil de 25 indicando que seguramente no la haya. Si revisamos el scatterplot podemos ver que estos valores de SPS y AD entran dentro del scope del modelo.

# Ejercicio 2

### (a) Gráfico de dispersión

```{r}
#install.packages("readxl")
library("readxl")
data2 = read.csv("lions.csv")
```

```{r}
library(ggplot2)
library(dplyr)

p = ggplot(data2, aes(age, prop.black))
p + geom_point(aes(shape = paste(ifelse(sex == "M", "males", "females"), ifelse(area == "N", "Ngorongoro", "Serengeti")))) + 
  scale_shape_manual(name = "", 
                     values = c(1, 19, 2, 17), 
                     labels = data2 %>%
                       group_by(sex, area) %>%
                       summarize(n = n()) %>%
                       mutate(label = paste0(ifelse(area == "N", "Ngorongoro", "Serengeti"), " ", ifelse(sex == "M", "males", "females"), "(n = ", n, ")")) %>%
                       pull(label)) +
  labs(x = "Age (yr)", y = "Proportion black", shape = "") +
  scale_x_continuous(breaks = seq(0, 16, 2), limits = c(0, 16)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  scale_fill_discrete(breaks=c('F', 'M')) +
  theme_classic() +
  theme(aspect.ratio = 0.5, legend.position = c(0.75, 0.3))
```

### (b) Modelos según área

```{r}
lmod_all = lm(prop.black ~ age + sex + area, data = data2)
summary(lmod_all)

data2_split_area = split(data2, f=data2$area)

lmod_N = lm(prop.black ~ age + sex, data = data2_split_area$N)
lmod_S = lm(prop.black ~ age + sex, data = data2_split_area$S)
summary(lmod_N)
summary(lmod_S)

```

En el modelo con todas las posibles variables y sin contrastar si existe interacción entre las variables, podemos observar que el sexo influye significativamente sobre la variable respuesta (proporción de negro en la nariz), con un pvalor = 0.0279.

Al separar por área, obtenemos los mismos resultados que en el artículo, en el que en la población Ngorongoroel sexo influye significativamente en la variable respuesta (pv = 0.04), mientras que en los Serengeti no influye (pv = 0.4). Podemos deducir que en el caso de los machos tienen una nariz más clara por el coeficiente estimado que es negativo (-0.16), es decir que el ser macho se relaciona significativamente con tener la nariz más clara.

### (c) Modelo leones macho

```{r}
data2_split_sex = split(data2, f = data2$sex)
lmod_male = lm(prop.black ~ age + area, data = data2_split_sex$M)
summary(lmod_male)
```

Confirmamos que para los machos existen diferencias significativas según el área (pv = 0.03), teniendo los Serengeti una nariz más oscura que los Ngorongoro (coef = 0.14).

```{r}
# Fit a linear regression model with an interaction term
lmod_male_interaction <- lm(prop.black ~ age * area, data = data2_split_sex$M)

# Create a sequence of ages to use for plotting
age_seq <- seq(min(data2_split_sex$M$age), max(data2_split_sex$M$age), length.out = 100)

# Predict proportion black for each area at each age
pred_N <- predict(lmod_male_interaction, newdata = data.frame(age = age_seq, area = "N"))
pred_S <- predict(lmod_male_interaction, newdata = data.frame(age = age_seq, area = "S"))

# Plot regression lines for each area
plot(data2_split_sex$M$age, data2_split_sex$M$prop.black, xlab = "Age", ylab = "Proportion Black")
lines(age_seq, pred_N, col = "red")
lines(age_seq, pred_S, col = "blue")
legend("bottomright", legend = c("Ngorongoro", "Serengeti"), col = c("red", "blue"), lty = 1)
```

Cabe destacar que para dibujar la regresión por áreas, hemos ajustado un modelo dónde se permite la interacción entre la edad y el área para permitir que la pendiente de regresión cambie según el área.

### (d) Predicción de la edad de una leona

No, ninguno de los modelos ajustados hasta el momento serviría para predecir la edad de una leona según su proporción de pigmentación. Hasta ahora hemos usado la pigmentación de la nariz como variable respuesta, que era explicada por la edad, área y sexo del león. No es posible simplemente "revertir" el modelo, necesitaríamos estimar un nuevo modelo dónde la variable respuesta fuera la edad, y la variable predictora fuera el color de la nariz.

El modelo que proponen en el artículo, utilizan la función arcsin para transformar la proporción de negro en la nariz, y hacerla más simétrica y adecuada para el estudio estadístico. Con esta transformación, los valores medios de proporción siguen una distribución normal, gracias a esto se puede realizar una regresión lineal. Se define de la siguiente manera: arcsin(x) = arcsin(x) = sin^(-1)(x). Cabe destacar que no aplicamos una transformación sqrt porque nuestros datos sabemos que estan seguro entre 0 y 1, por lo tanto no se requiere esta transformación. 

```{r}
library(stats)

# Aplicamos la transformación sólo a 
data2_split_sex$F$prop.black.transformed = asin(data2_split_sex$F$prop.black)

lmod_age = lm(age ~ prop.black.transformed, data = data2_split_sex$F)

# Compute the predicted age on the transformed scale

# Define the proportion black for which to make the prediction
prop_black = 0.5
prop_black_transformed <- asin(prop_black)

# Compute the predicted age and confidence intervals
predicted_age <- predict(lmod_age, newdata = data.frame(prop.black.transformed = prop_black_transformed))
ci_95 <- predict(lmod_age, newdata = data.frame(prop.black.transformed = prop_black_transformed), interval = "prediction", level = 0.95)
ci_75 <- predict(lmod_age, newdata = data.frame(prop.black.transformed = prop_black_transformed), interval = "prediction", level = 0.75)
ci_50 <- predict(lmod_age, newdata = data.frame(prop.black.transformed = prop_black_transformed), interval = "prediction", level = 0.50)

# Compute se
summary_lmod_age <- summary(lmod_age)
se_predicted_age <- summary_lmod_age$sigma * sqrt(1 + 1/nrow(data2_split_sex$F) + (prop_black_transformed - mean(data2_split_sex$F$prop.black.transformed))^2/var(data2_split_sex$F$prop.black.transformed))

# Create a data frame with the predicted age and confidence intervals
result_table <- data.frame("Proportion black" = prop_black, 
                           "Estimated age in years" =paste(round(predicted_age,2), "(", round(se_predicted_age,2), ")"),
                           "95% CI" = paste(round(ci_95[2],2), round(ci_95[3],2), sep = "-"),
                           "75% CI" = paste(round(ci_75[2],2), round(ci_75[3],2), sep = "-"),
                           "50% CI" = paste(round(ci_50[2],2), round(ci_50[3],2), sep = "-"))

library(knitr)

new_names = c("Proportion black", "Estimated age in years (s.e.)", "95% p.i.", "75% p.i.", "50% p.i.")

names(result_table) <- new_names

# Create a table using the kable function from the knitr package
kable(result_table, format = "markdown")

```

Se o standard error es una medida de la variabilidad de los errores de predicción de la variable dependiente a partir de las variables independientes. Se calcula como la desviación estándar de los residuos de la regresión (diferencias entre los valores predichos y los valores observados) dividida por la raíz cuadrada del número de observaciones.En resumen, el error estándar indica la precisión de las predicciones de la variable dependiente y es una medida importante para evaluar la calidad de un modelo de regresión lineal. Un error estándar más bajo indica una mayor precisión en las predicciones del modelo.

# Ejercicio 3

### (a) Gauss-Markov y normaliada de residuos

### (b) Variable respuesta proporción

### (c) Transformación de la variable

### (d) Ajuste modelo transformado

### (e) Discusión uso arcsin